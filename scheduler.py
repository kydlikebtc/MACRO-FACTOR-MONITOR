"""
æ—¥ç»´åº¦è‡ªåŠ¨æ›´æ–°è°ƒåº¦å™¨
æ”¯æŒä¸‰ç§è¿è¡Œæ¨¡å¼ï¼š
  1. python scheduler.py          â†’ æŒç»­è¿è¡Œï¼Œæ¯æ—¥å®šæ—¶æ›´æ–°
  2. python scheduler.py --once   â†’ å•æ¬¡æ‰§è¡Œ
  3. crontab é…ç½®                 â†’ ç³»ç»Ÿçº§å®šæ—¶ä»»åŠ¡

v3.0 å˜æ›´:
  - åŸå­å†™å…¥é˜²æ­¢æ–­ç”µæŸå
  - æå–å…¬å…±å‡½æ•°é¿å… run.py é‡å¤æ‰§è¡Œ
  - æ”¯æŒæ—¶åŒºæ„ŸçŸ¥è°ƒåº¦
"""
import os
import sys
import time
import json
import logging
import argparse
from datetime import datetime, timedelta
from pathlib import Path

# ç¡®ä¿èƒ½å¯¼å…¥åŒç›®å½•æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from swarm import MacroFactorSwarm
from dashboard import generate_dashboard
from config import SCHEDULE

logger = logging.getLogger("scheduler")

OUTPUT_DIR = os.path.dirname(os.path.abspath(__file__))


def atomic_write(path: str, content: str):
    """åŸå­å†™å…¥: å†™ä¸´æ—¶æ–‡ä»¶å† renameï¼Œé˜²æ­¢æ–­ç”µæŸå"""
    tmp_path = path + ".tmp"
    with open(tmp_path, "w", encoding="utf-8") as f:
        f.write(content)
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp_path, path)  # åŸå­æ“ä½œ


def build_report_json(report) -> dict:
    """ä» SwarmReport æ„å»º JSON å­—å…¸ (å…¬å…±å‡½æ•°ï¼Œé¿å…é‡å¤ä»£ç )"""
    json_data = {
        "timestamp": report.timestamp.isoformat(),
        "overall_signal": report.overall_signal.value,
        "weighted_score": report.weighted_score,
        "bull_count": len(report.bull_factors),
        "neutral_count": len(report.neutral_factors),
        "bear_count": len(report.bear_factors),
        "bull_factors": report.bull_factors,
        "neutral_factors": report.neutral_factors,
        "bear_factors": report.bear_factors,
        "live_data_points": report.live_count,
        "fallback_data_points": report.fallback_count,
        "agents": [],
    }
    for r in report.agent_results:
        agent_data = {
            "name": r.agent_name,
            "category": r.category.value,
            "signal": r.signal.value,
            "confidence": r.confidence,
            "summary": r.summary,
            "formula": r.formula,
            "error": r.error,
            "factors": [
                {
                    "name": f.name,
                    "name_en": f.name_en,
                    "value": f.current_value,
                    "unit": f.unit,
                    "signal": f.signal.value,
                    "source_name": f.source.name if f.source else "",
                    "source_url": f.source.url if f.source else "",
                    "interpretation": f.interpretation,
                    "is_live": f.is_live,
                }
                for f in r.factors
            ],
        }
        json_data["agents"].append(agent_data)
    return json_data


def run_update(fred_api_key=None, output_dir=None):
    """æ‰§è¡Œä¸€æ¬¡å®Œæ•´æ›´æ–° (åŸå­å†™å…¥)"""
    out = output_dir or OUTPUT_DIR
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“… å®šæ—¶æ›´æ–°å¯åŠ¨ | {ts}")
    logger.info(f"{'='*60}")

    try:
        swarm = MacroFactorSwarm(fred_api_key=fred_api_key)
        report = swarm.run()

        # ä¿å­˜ HTML (åŸå­å†™å…¥)
        html = generate_dashboard(report)
        html_path = os.path.join(out, "dashboard.html")
        atomic_write(html_path, html)
        logger.info(f"ğŸŒ Dashboard â†’ {html_path}")

        # ä¿å­˜ JSON (åŸå­å†™å…¥)
        json_data = build_report_json(report)
        json_path = os.path.join(out, "report.json")
        atomic_write(json_path, json.dumps(json_data, ensure_ascii=False, indent=2))
        logger.info(f"ğŸ“„ Report  â†’ {json_path}")

        # æ—¥å­˜æ¡£ (åŸå­å†™å…¥)
        date_str = datetime.now().strftime("%Y%m%d")
        archive_dir = os.path.join(out, "archive")
        os.makedirs(archive_dir, exist_ok=True)
        archive_path = os.path.join(archive_dir, f"report_{date_str}.json")
        atomic_write(archive_path, json.dumps(json_data, ensure_ascii=False, indent=2))
        logger.info(f"ğŸ“¦ Archive â†’ {archive_path}")

        # æ•°æ®æ–°é²œåº¦å‘Šè­¦
        total = report.live_count + report.fallback_count
        if report.live_count == 0 and total > 0:
            logger.warning(f"âš ï¸  æ•°æ®å‘Šè­¦: 0/{total} live data! æ‰€æœ‰æ•°æ®æºä¸å¯è¾¾")
        elif report.fallback_count > 0:
            logger.info(f"ğŸ“Š æ•°æ®çŠ¶æ€: {report.live_count}/{total} live, {report.fallback_count} fallback")

        logger.info(f"âœ… æ›´æ–°å®Œæˆ | ä¿¡å·: {report.overall_signal.cn}")
        return True

    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {e}", exc_info=True)
        return False


def run_daemon(fred_api_key=None, output_dir=None):
    """
    å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ - æ¯æ—¥å®šæ—¶æ‰§è¡Œ
    é»˜è®¤: æ¯å¤© 08:30 EST è¿è¡Œ
    """
    hour = SCHEDULE["update_hour"]
    minute = SCHEDULE["update_minute"]

    # å°è¯•ä½¿ç”¨æ—¶åŒºæ„ŸçŸ¥è°ƒåº¦
    tz = None
    try:
        from zoneinfo import ZoneInfo
        tz = ZoneInfo(SCHEDULE["timezone"])
        logger.info(f"ğŸ• å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨ | æ¯æ—¥ {hour:02d}:{minute:02d} {SCHEDULE['timezone']} æ›´æ–°")
    except (ImportError, KeyError):
        logger.info(f"ğŸ• å®ˆæŠ¤è¿›ç¨‹å¯åŠ¨ | æ¯æ—¥ {hour:02d}:{minute:02d} æœ¬åœ°æ—¶é—´æ›´æ–°")
        logger.warning("   zoneinfo ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")

    logger.info(f"   æŒ‰ Ctrl+C åœæ­¢\n")

    # å¯åŠ¨æ—¶å…ˆæ‰§è¡Œä¸€æ¬¡
    run_update(fred_api_key, output_dir)

    while True:
        now = datetime.now(tz) if tz else datetime.now()
        # è®¡ç®—ä¸‹æ¬¡è¿è¡Œæ—¶é—´
        target = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
        if target <= now:
            target += timedelta(days=1)

        wait_sec = (target - now).total_seconds()
        logger.info(f"â³ ä¸‹æ¬¡æ›´æ–°: {target.strftime('%Y-%m-%d %H:%M %Z')} ({wait_sec/3600:.1f}h)")

        try:
            time.sleep(wait_sec)
        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ å®ˆæŠ¤è¿›ç¨‹å·²åœæ­¢")
            break

        # æ‰§è¡Œæ›´æ–° (å¸¦æŒ‡æ•°é€€é¿é‡è¯•)
        retry_count = SCHEDULE.get("retry_count", 3)
        for attempt in range(retry_count):
            if run_update(fred_api_key, output_dir):
                break
            delay = SCHEDULE.get("retry_delay_sec", 60) * (2 ** attempt)
            logger.warning(f"é‡è¯• {attempt+1}/{retry_count}... (ç­‰å¾… {delay}s)")
            time.sleep(delay)


def print_cron_help():
    """æ‰“å° crontab é…ç½®å¸®åŠ©"""
    script = os.path.abspath(__file__).replace(" ", "\\ ")
    h = SCHEDULE["update_hour"]
    m = SCHEDULE["update_minute"]
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“… Crontab é…ç½®æŒ‡å—                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                          â•‘
â•‘  ç¼–è¾‘ crontab:                                           â•‘
â•‘    crontab -e                                            â•‘
â•‘                                                          â•‘
â•‘  æ·»åŠ ä»¥ä¸‹è¡Œ (æ¯æ—¥ {h:02d}:{m:02d} æ‰§è¡Œ):                       â•‘
â•‘    {m} {h} * * * cd {os.path.dirname(script)} && python3 scheduler.py --once  â•‘
â•‘                                                          â•‘
â•‘  æŸ¥çœ‹å·²æœ‰ä»»åŠ¡:                                             â•‘
â•‘    crontab -l                                            â•‘
â•‘                                                          â•‘
â•‘  å¦‚éœ€ FRED API Key (ç¯å¢ƒå˜é‡æ–¹å¼):                         â•‘
â•‘    {m} {h} * * * cd {os.path.dirname(script)} && FRED_API_KEY=YOUR_KEY python3 scheduler.py --once  â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def main():
    parser = argparse.ArgumentParser(description="å®è§‚å› å­ç›‘æ§ - å®šæ—¶æ›´æ–°è°ƒåº¦å™¨")
    parser.add_argument("--once", action="store_true", help="å•æ¬¡æ‰§è¡Œåé€€å‡º")
    parser.add_argument("--key", type=str, default=None, help="FRED API Key")
    parser.add_argument("--output", type=str, default=None, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--cron", action="store_true", help="æ˜¾ç¤º crontab é…ç½®å¸®åŠ©")
    args = parser.parse_args()

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(name)s] %(message)s",
        datefmt="%H:%M:%S",
    )

    # æ”¯æŒç¯å¢ƒå˜é‡ä¼ å…¥ API Key
    api_key = args.key or os.environ.get("FRED_API_KEY")

    if args.cron:
        print_cron_help()
        return

    if args.once:
        success = run_update(api_key, args.output)
        sys.exit(0 if success else 1)

    run_daemon(api_key, args.output)


if __name__ == "__main__":
    main()
